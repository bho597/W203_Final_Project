{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7acf91db",
   "metadata": {},
   "source": [
    "# Image Classification with Hybrid Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8123afdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-19 10:08:24.647845: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-19 10:08:24.847446: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-04-19 10:08:28.059103: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/cuda/lib:/usr/local/lib/x86_64-linux-gnu:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2023-04-19 10:08:28.059264: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/cuda/lib:/usr/local/lib/x86_64-linux-gnu:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2023-04-19 10:08:28.059280: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import csv\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f46bb64-6a91-4a30-a65f-32cdeb664be0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.cpu_count())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae0bee94-40c8-4de3-81ff-fe5f90d73032",
   "metadata": {},
   "source": [
    "### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ff78436-5644-4338-b6a9-4f8bb6dd922d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10.5 s, sys: 878 ms, total: 11.3 s\n",
      "Wall time: 11.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Load the compressed array from disk\n",
    "images_mini = np.load('CNN_Xs_downsample_forvgg16.npz')['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e5b23f05-34bd-40f6-b7cb-83c5a78b2436",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the labels from disk\n",
    "with open('CNN_labels_downsampled_forvgg16.csv', 'r') as file:\n",
    "    reader = csv.reader(file)\n",
    "    labels_mini = list(reader)[0]\n",
    "    labels_mini = [int(x) for x in labels_mini]\n",
    "    y_mini= np.array(labels_mini)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f601ebe-8450-4bf6-a40c-5d0cb72361e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images_mini.shape: (5600, 224, 224, 3)\n",
      "\n",
      "number of labels: 5600\n",
      "\n",
      "number of positive cancer cases: 600\n"
     ]
    }
   ],
   "source": [
    "print('images_mini.shape:', images_mini.shape)\n",
    "print('\\nnumber of labels:', len(labels_mini))\n",
    "print('\\nnumber of positive cancer cases:', sum(labels_mini))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1cd1355-80fb-4a20-8613-7ec398b3dc47",
   "metadata": {},
   "source": [
    "### Normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dcafb559-2117-4729-ab6f-1cecfbd8fa73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original max pixel value: 255.0\n",
      "Confirm min pixel value is 0: 0.0\n"
     ]
    }
   ],
   "source": [
    "print('Original max pixel value:', images_mini.max())\n",
    "print('Confirm min pixel value is 0:', images_mini.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0aa25385-4e89-46bf-9857-9dfd6b044644",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalize image pixel values\n",
    "images_mini_norm = images_mini / images_mini.max() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "69656465-56d3-4d02-8cd6-32195ac621c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New max pixel value: 1.0\n",
      "Confirm min pixel value is 0: 0.0\n"
     ]
    }
   ],
   "source": [
    "print('New max pixel value:', images_mini_norm.max())\n",
    "print('Confirm min pixel value is 0:', images_mini_norm.min())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "897e0c1e-d694-45fb-aa5d-6612ecdabb48",
   "metadata": {},
   "source": [
    "### Reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a9417b9d-badf-475e-9d78-ccb55e805193",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5600, 224, 224, 3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_mini_norm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "db2a8f21-8ddb-4048-9631-c7843660f81c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5600, 224, 224, 1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr_mean = np.mean(images_mini_norm, axis=-1)\n",
    "arr_mean.shape\n",
    "resized_images_mini = np.expand_dims(arr_mean, axis=-1)\n",
    "resized_images_mini.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "291c052c-4af3-49c6-afdc-77601cea2d05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original max pixel value: 1.0\n",
      "Confirm min pixel value is 0: 0.0\n"
     ]
    }
   ],
   "source": [
    "print('Original max pixel value:', resized_images_mini.max())\n",
    "print('Confirm min pixel value is 0:', resized_images_mini.min())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38385b7b-ebb5-4211-be81-dc981201444d",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b8c19234",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 1234"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b0a50a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(random_state)\n",
    "tf.random.set_seed(random_state)\n",
    "np.random.seed(random_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51102930-a481-438e-a03b-fd25ec6195b4",
   "metadata": {},
   "source": [
    "### Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d9b44533-2298-4333-8a4f-3b352850c75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X= resized_images_mini\n",
    "y = y_mini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3d132553-c9b1-4745-af93-bcb5cbfe10db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4480, 224, 224, 1)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=random_state)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aa3f678d-4f6d-4fc3-8b2d-c7a428ea6060",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-19 10:08:52.560695: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/cuda/lib:/usr/local/lib/x86_64-linux-gnu:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2023-04-19 10:08:52.560749: W tensorflow/stream_executor/cuda/cuda_driver.cc:263] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-04-19 10:08:52.560788: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (099efb1cae5d): /proc/driver/nvidia/version does not exist\n",
      "2023-04-19 10:08:52.561255: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "def preprocess_augm(X_train, y_train):\n",
    "    \n",
    "    # Augment only cancer=1 data\n",
    "    X_train_w_cancer = X_train[y_train == 1, :, :, :]\n",
    "    y_train_w_cancer = y_train[y_train == 1]\n",
    "    \n",
    "    ### image augmentation on training data ###\n",
    "    ###########################################\n",
    "    # adjust brightness\n",
    "    X_train_augm1 = tf.image.adjust_brightness(X_train_w_cancer, delta=.1)\n",
    "    X_train_augm2 = tf.image.adjust_brightness(X_train_w_cancer, delta=.2)\n",
    "    \n",
    "    # adjust contrast\n",
    "    X_train_augm5 = tf.image.adjust_contrast(X_train_w_cancer, contrast_factor=1)\n",
    "    X_train_augm6 = tf.image.adjust_contrast(X_train_w_cancer, contrast_factor=2)\n",
    "\n",
    "    # random flip\n",
    "    X_train_augm8 = tf.image.random_flip_left_right(X_train_w_cancer)\n",
    "    \n",
    "    # concatenate augmented X_train data\n",
    "    X_train_augm = tf.concat([X_train_augm1, X_train_augm2, X_train_augm5,\n",
    "                        X_train_augm6, X_train_augm8],axis=0)\n",
    "    order = []\n",
    "    for i in range(5):\n",
    "        order += [j for j in range(len(X_train_w_cancer))]\n",
    "    \n",
    "    # concatenate y_train (note the label is preserved)\n",
    "    y_train_augm = tf.convert_to_tensor(np.ones(len(X_train_augm)))\n",
    "    \n",
    "    # shuffle X_train and y_train, i.e., shuffle two tensors in the same order\n",
    "    shuffle = tf.random.shuffle(tf.range(tf.shape(X_train_augm)[0], dtype=tf.int32))\n",
    "    X_train_augm = tf.gather(X_train_augm, shuffle)\n",
    "    y_train_augm = tf.gather(y_train_augm, shuffle)\n",
    "    \n",
    "    shuffled_order = tf.gather(order, shuffle)\n",
    "\n",
    "    return X_train_augm, y_train_augm, shuffled_order.numpy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "92a4de07-84c7-4f29-a3a5-faebac5c008b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_augm_part2(X_train, y_train, X_train_augm, y_train_augm, order, n_augm):\n",
    "    X_train_augm = X_train_augm[0:n_augm]\n",
    "    y_train_augm = y_train_augm[0:n_augm]\n",
    "    selected_order = order[0:n_augm]\n",
    "    \n",
    "    X_train_order = [j for j in range(tf.shape(X_train)[0])]\n",
    "    selected_order = np.concatenate((np.array(X_train_order), selected_order))\n",
    "    \n",
    "    \n",
    "    X_train = tf.concat([X_train, X_train_augm],axis=0)\n",
    "    y_train = tf.concat([y_train, y_train_augm],axis=0)\n",
    "    \n",
    "    # shuffle X_train and y_train, i.e., shuffle two tensors in the same order\n",
    "    shuffle = tf.random.shuffle(tf.range(tf.shape(X_train)[0], dtype=tf.int32))\n",
    "    X_train = tf.gather(X_train, shuffle)\n",
    "    y_train = tf.gather(y_train, shuffle).numpy() #also transforms y_train to numpy array\n",
    "    \n",
    "    groups = tf.gather(selected_order, shuffle)\n",
    "    \n",
    "    return X_train, y_train, groups.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72dea81a-4dbc-4cd5-9412-8f9b87b24d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the function\n",
    "# preprocess_augm(X_train, y_train)\n",
    "X_train_augm, y_train_augm, order = preprocess_augm(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c0a6ef6d-c141-4bb8-b9f8-96af89b86928",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_aug = 1800\n",
    "X_train, y_train, groups = preprocess_augm_part2(X_train, y_train, X_train_augm, y_train_augm, order, n_augm=num_aug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "12cc1f2b-6b6b-4dac-b2cf-abf39c54dcfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape\n",
    "X_train = np.reshape(X_train, (len(X_train), -1))\n",
    "X_test = np.reshape(X_test, (len(X_test), -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "50fbff8f-3e6c-45f8-a716-e38176ada9b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6280, 50176)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afd0132e",
   "metadata": {},
   "source": [
    "## Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2916877f-f8b1-40b5-bfd5-825633735df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(max_iter = 1000)\n",
    "\n",
    "knn = KNeighborsClassifier(\n",
    "    n_jobs=-1,\n",
    "    **{'weights': 'distance', 'p': 1, 'n_neighbors': 25, 'algorithm': 'auto'}\n",
    ")\n",
    "\n",
    "\n",
    "gnb = GaussianNB(\n",
    "    **{'var_smoothing': 0.0013768459590682242}\n",
    ")\n",
    "\n",
    "dt = DecisionTreeClassifier(\n",
    "    **{'min_samples_split': 2, 'max_features': 0.1, 'max_depth': 15, 'criterion': 'gini'}\n",
    ")\n",
    "\n",
    "rf = RandomForestClassifier(\n",
    "    **{'n_estimators': 100, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'max_depth': 30}\n",
    ")\n",
    "\n",
    "lsvm = LinearSVC(\n",
    "    **{'tol': 0.00031622776601683794, 'penalty': 'l2', 'loss': 'squared_hinge', 'dual': False, 'C': 0.01}\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e5739901-7731-4190-8905-5e87dd49b774",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = [\n",
    "    ['KNN', knn],\n",
    "    ['LogisticRegression', lr],\n",
    "    ['NaiveBayes', gnb],\n",
    "    ['DecisionTree',dt],\n",
    "    ['RandomForest', rf], \n",
    "    ['Linear SVM', lsvm],\n",
    "    # ['XGB :', xgb],\n",
    "]\n",
    "\n",
    "voting_clf = VotingClassifier(classifiers, voting='hard')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0466fba4-e847-4b9b-b547-d1d2b618f99e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6280, 50176)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "063f3153-8bd7-40d5-bac2-1b217bb23182",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6280,)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8e0905e2",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[['KNN',\n",
       "                              KNeighborsClassifier(n_jobs=-1, n_neighbors=25,\n",
       "                                                   p=1, weights='distance')],\n",
       "                             ['LogisticRegression',\n",
       "                              LogisticRegression(max_iter=1000)],\n",
       "                             ['NaiveBayes',\n",
       "                              GaussianNB(var_smoothing=0.0013768459590682242)],\n",
       "                             ['DecisionTree',\n",
       "                              DecisionTreeClassifier(max_depth=15,\n",
       "                                                     max_features=0.1)],\n",
       "                             ['RandomForest',\n",
       "                              RandomForestClassifier(max_depth=30,\n",
       "                                                     max_features='log2',\n",
       "                                                     min_samples_split=5)],\n",
       "                             ['Linear SVM',\n",
       "                              LinearSVC(C=0.01, dual=False,\n",
       "                                        tol=0.00031622776601683794)]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "voting_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d9468c-ad72-46e3-8c3f-8020b7028596",
   "metadata": {},
   "source": [
    "### Scoring"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78013ea8-609d-49a7-8972-fdebc39dd3ab",
   "metadata": {},
   "source": [
    "### Hard Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6352eb38-8885-4b17-a8fc-e1de69a630cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train acc score: 0.995\n",
      "Test acc score: 0.892\n"
     ]
    }
   ],
   "source": [
    "train_roc = voting_clf.score(X_train, y_train)\n",
    "print(f\"Train acc score: {train_roc:.3f}\")\n",
    "\n",
    "# Evaluate the test accuracy\n",
    "test_roc = voting_clf.score(X_test, y_test)\n",
    "print(f\"Test acc score: {test_roc:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9a23251e-7d2f-4fee-8672-1a0463c895d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train = voting_clf.predict(X_train)\n",
    "y_pred_test = voting_clf.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d46fb829",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train f1 score: 0.993\n",
      "Test f1 score: 0.000\n"
     ]
    }
   ],
   "source": [
    "train_roc = f1_score(y_train, y_pred_train)\n",
    "print(f\"Train f1 score: {train_roc:.3f}\")\n",
    "\n",
    "# Evaluate the test accuracy\n",
    "test_roc = f1_score(y_test, y_pred_test)\n",
    "print(f\"Test f1 score: {test_roc:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7f07b668-274a-424a-a2fb-d2b7a061ec24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train precision score: 1.000\n",
      "Test precision score: 0.000\n",
      "Train recall score: 0.987\n",
      "Test recall score: 0.000\n"
     ]
    }
   ],
   "source": [
    "train_roc = precision_score(y_train, y_pred_train)\n",
    "print(f\"Train precision score: {train_roc:.3f}\")\n",
    "\n",
    "# Evaluate the test accuracy\n",
    "test_roc = precision_score(y_test, y_pred_test)\n",
    "print(f\"Test precision score: {test_roc:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1087eb5f-7ee5-47bd-a5c0-ccc7e088a82d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_roc = recall_score(y_train, y_pred_train)\n",
    "print(f\"Train recall score: {train_roc:.3f}\")\n",
    "\n",
    "# Evaluate the test accuracy\n",
    "test_roc = recall_score(y_test, y_pred_test)\n",
    "print(f\"Test recall score: {test_roc:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7540776f-cd08-42b0-afe2-bc859964a948",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1/2105884560.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mroc_auc_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain_roc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroc_auc_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Train f1 score: {train_roc:.3f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Evaluate the test accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'y_train' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "train_roc = roc_auc_score(y_train, y_pred_train)\n",
    "print(f\"Train f1 score: {train_roc:.3f}\")\n",
    "\n",
    "# Evaluate the test accuracy\n",
    "test_roc = roc_auc_score(y_test, y_pred_test)\n",
    "print(f\"Test f1 score: {test_roc:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd0883c4-055e-4a14-a9b0-9b5ef9d684fa",
   "metadata": {},
   "source": [
    "### Soft Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "37fe47cc-ebdc-42ef-a63a-f915d100925b",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = [\n",
    "    ['KNN', knn],\n",
    "    ['LogisticRegression', lr],\n",
    "    ['NaiveBayes', gnb],\n",
    "    ['DecisionTree',dt],\n",
    "    ['RandomForest', rf], \n",
    "    # ['Linear SVM', lsvm],\n",
    "    # ['XGB :', xgb],\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d948ea39-10f3-42c0-b39b-111bf930b8e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "soft_voting_clf = VotingClassifier(classifiers, voting='soft')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "23414b7d-c9f3-4c49-ba8a-d959fb89a58e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[['KNN',\n",
       "                              KNeighborsClassifier(n_jobs=-1, n_neighbors=25,\n",
       "                                                   p=1, weights='distance')],\n",
       "                             ['LogisticRegression',\n",
       "                              LogisticRegression(max_iter=1000)],\n",
       "                             ['NaiveBayes',\n",
       "                              GaussianNB(var_smoothing=0.0013768459590682242)],\n",
       "                             ['DecisionTree',\n",
       "                              DecisionTreeClassifier(max_depth=15,\n",
       "                                                     max_features=0.1)],\n",
       "                             ['RandomForest',\n",
       "                              RandomForestClassifier(max_depth=30,\n",
       "                                                     max_features='log2',\n",
       "                                                     min_samples_split=5)]],\n",
       "                 voting='soft')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soft_voting_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6ec997ee-dd88-46d9-8cae-ccffa4032de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train = soft_voting_clf.predict(X_train)\n",
    "y_pred_test = soft_voting_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "541ad980-f387-416a-8b54-138d6f44b5e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train f1 score: 0.997\n",
      "Test f1 score: 0.030\n"
     ]
    }
   ],
   "source": [
    "train_roc = f1_score(y_train, y_pred_train)\n",
    "print(f\"Train f1 score: {train_roc:.3f}\")\n",
    "\n",
    "# Evaluate the test accuracy\n",
    "test_roc = f1_score(y_test, y_pred_test)\n",
    "print(f\"Test f1 score: {test_roc:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3bdc0233-af43-41a1-8c77-ef69ceea7b1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train precision score: 1.000\n",
      "Test precision score: 0.125\n",
      "Train recall score: 0.994\n",
      "Test recall score: 0.017\n"
     ]
    }
   ],
   "source": [
    "train_roc = precision_score(y_train, y_pred_train)\n",
    "print(f\"Train precision score: {train_roc:.3f}\")\n",
    "\n",
    "# Evaluate the test accuracy\n",
    "test_roc = precision_score(y_test, y_pred_test)\n",
    "print(f\"Test precision score: {test_roc:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb282ef8-1e33-4811-8b3c-925dc139f8a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_roc = recall_score(y_train, y_pred_train)\n",
    "print(f\"Train recall score: {train_roc:.3f}\")\n",
    "\n",
    "# Evaluate the test accuracy\n",
    "test_roc = recall_score(y_test, y_pred_test)\n",
    "print(f\"Test recall score: {test_roc:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1c5a47ad-e98c-47ff-be21-b2d101711de8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train f1 score: 0.997\n",
      "Test f1 score: 0.501\n"
     ]
    }
   ],
   "source": [
    "train_roc = roc_auc_score(y_train, y_pred_train)\n",
    "print(f\"Train ROC_AUC score: {train_roc:.3f}\")\n",
    "\n",
    "# Evaluate the test accuracy\n",
    "test_roc = roc_auc_score(y_test, y_pred_test)\n",
    "print(f\"Test ROC_AUC score: {test_roc:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8bfb9e3-3efc-4797-a18d-407fd63872d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow 2 (Local)",
   "language": "python",
   "name": "local-tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
